file:: [动手学深度学习（2）_1676132768030_0.pdf](../assets/动手学深度学习（2）_1676132768030_0.pdf)
file-path:: ../assets/动手学深度学习（2）_1676132768030_0.pdf

- #深度学习
# 1.  引言
collapsed:: true
	- # 1.3 各种机器学习问题
	  hl-page:: 46
	  ls-type:: annotation
	  id:: 63e7c479-c339-4e04-b46d-ba5f4e2297d1
	  hl-color:: yellow
	  collapsed:: true
		- ## 1.3.1 监督学习
		  ls-type:: annotation
		  hl-page:: 46
		  hl-color:: red
		  id:: 63e7c488-aa68-4914-9f40-ddc1ce2a21bf
			- 监督学习（supervised learning）擅⻓在“给定输入特征”的情况下预测标签。每个“特征-标签”对都称为一个样本（example）。有时，即使标签是未知的，样本也可以指代输入特征。我们的目标是生成一个模型，能够将任何输入特征映射到标签，即预测。举一个具体的例子：假设我们需要预测患者是否会心脏病发作，那么观察结果“心脏病发作”或“心脏病没有发作”将是我们的标签。输入特征可能是生命体征，如心率、舒张压和收缩压。
			  ls-type:: annotation
			  hl-page:: 46
			  hl-color:: purple
			  id:: 63e7c4a9-4d8c-4f58-bc60-d5810f38c7be
			- 监督学习之所以发挥作用，是因为在训练参数时，我们为模型提供了一个数据集，其中每个样本都有真实的标签。
			  ls-type:: annotation
			  hl-page:: 46
			  hl-color:: purple
			  id:: 63e7c566-cbfd-4713-9058-bcba01e077e9
			- 非正式地说，监督学习的学习过程如下所示。首先，从已知大量数据样本中随机选取一个子集，为每个样本获取基本的真实标签。有时，这些样本已有标签（例如，患者是否在下一年内康复？）；有时，我们可能需要人工标记数据（例如，将图像分类）。这些输入和相应的标签一起构成了训练数据集。随后，我们选择有监督的学习算法，它将训练数据集作为输入，并输出一个“完成学习模型”。最后，我们将之前没⻅过的样本特征放到这个“完成学习模型”中，使用模型的输出作为相应标签的预测。整个监督学习过程在 图1.3.1 中绘制。
			  ls-type:: annotation
			  hl-page:: 46
			  hl-color:: purple
			  id:: 63e7c64f-7cd2-4959-af75-e6d2051f96cc
			- [:span]
			  ls-type:: annotation
			  hl-page:: 46
			  hl-color:: purple
			  id:: 63e7c658-f107-4306-964c-818f519ba55a
			  hl-type:: area
			  hl-stamp:: 1676133975721
			- ### 回归
			  ls-type:: annotation
			  hl-page:: 47
			  hl-color:: green
			  id:: 63e7c68a-6887-424e-98fd-7beced588ca4
				- 回归（regression）是最简单的监督学习任务之一。
				  ls-type:: annotation
				  hl-page:: 47
				  hl-color:: purple
				  id:: 63e7c7dc-e497-4ac2-94cf-5aea9a50963c
				- 本质上是输出决定的。假设你在市场上寻找新房子，你可能需要估计一栋房子的公平市场价值。销售价格，即标签，是一个数值。当标签取任意数值时，我们称之为回归问题。
				  ls-type:: annotation
				  hl-page:: 47
				  hl-color:: purple
				  id:: 63e7c7ec-331e-48e5-949c-4ed41caa93ea
				- 生活中的许多问题都可归类为回归问题。比如，预测用戶对一部电影的评分可以被认为是一个回归问题。这里有一个小插曲，如果你在2009年设计了一个很棒的算法来预测电影评分，你可能会赢得100万美元的奈⻜奖12。再比如，预测病人在医院的住院时间也是一个回归问题。总而言之，判断回归问题的一个很好的经验法则是，任何有关“多少”的问题很可能就是回归问题。
				  ls-type:: annotation
				  hl-page:: 47
				  hl-color:: purple
				  id:: 63e7c7fb-5e81-449b-a4ac-bdb5ff84395e
			- ### 分类
			  ls-type:: annotation
			  hl-page:: 47
			  hl-color:: green
			  id:: 63e7c842-688e-4527-9c62-a96e13dbc6cd
				- 虽然回归模型可以很好地解决“有多少？”的问题，但是很多问题并非如此。例如，一家银行希望在其移动应用程序中添加支票扫描功能。具体地说，这款应用程序能够自动理解从图像中看到的文本，并将手写字符映射到对应的已知字符之上。这种“哪一个？”的问题叫做分类（classification）问题。在分类问题中，我们希望模型能够预测样本属于哪个类别（category，正式称为类（class））。
				  ls-type:: annotation
				  hl-page:: 47
				  hl-color:: purple
				  id:: 63e7c8f5-870e-452c-8899-194c73571660
				- 在回归中，我们训练一个回归函数来输出一个数值；而在分类中，我们训练一个分类器，它的输出即为预测的类别。
				  ls-type:: annotation
				  hl-page:: 47
				  hl-color:: purple
				  id:: 63e7c910-24ba-4c7f-9304-48c8eb77e039
				- 最简单的分类问题是只有两类，我们称之为“==二元分类==”。
				  ls-type:: annotation
				  hl-page:: 47
				  hl-color:: purple
				  id:: 63e7c97b-2bc9-4a5e-8017-3c63341a30af
				- 当我们有两个以上的类别时，我们把这个问题称为==多元分类==（multiclass classification）问题。
				  ls-type:: annotation
				  hl-page:: 48
				  hl-color:: purple
				  id:: 63e7c981-467f-4d0b-ab5a-208dc3c2a011
				- 分类可能变得比二元分类、多元分类复杂得多。例如，有一些分类任务的变体可以用于寻找层次结构，层次结构假定在许多类之间存在某种关系。因此，并不是所有的错误都是均等的。我们宁愿错误地分入一个相关的类别，也不愿错误地分入一个遥远的类别，这通常被称为==层次分类==(hierarchical classification)。
				  ls-type:: annotation
				  hl-page:: 48
				  hl-color:: purple
				  id:: 63e7cabd-e36b-4f46-8dff-09e9e38a87cb
				- 与解决回归问题不同，分类问题的常⻅损失函数被称为交叉熵（cross-entropy）
				  ls-type:: annotation
				  hl-page:: 48
				  hl-color:: purple
				  id:: 63e7c999-c93b-46c9-b204-7269262fc4f4
					- 为什么呢？
						- 现在，请你训练一个毒蘑菇检测分类器，根据照片预测蘑菇是否有毒。假设这个分类器输出 图1.3.2 包含死帽蕈的概率是0.2。换句话说，分类器80%确定我们的蘑菇不是死帽蕈。尽管如此，我们也不会吃它，因为我们不值得冒20%的死亡⻛险。换句话说，不确定⻛险的影响远远大于收益。因此，我们需要将“预期⻛险”作为损失函数。也就是说，我们需要将结果的概率乘以与之相关的收益（或伤害）。在这种情况下，⻝用蘑菇造成的损失为0.2 × ∞ + 0.8 × 0 = ∞，而丢弃蘑菇的损失为0.2 × 0 + 0.8 × 1 = 0.8。
						  ls-type:: annotation
						  hl-page:: 48
						  hl-color:: purple
						  id:: 63e7c9fb-8e5c-4d2b-98cc-d154674f57e8
			- ### 标记
			  hl-page:: 49
			  ls-type:: annotation
			  id:: 63e7cba4-8d75-4ac0-ba8e-5aa195205530
			  hl-color:: green
				- 我们可能想让模型描绘输入图像的内容，一只猫、一只狗、一头驴，还有一只公鸡。
				  ls-type:: annotation
				  hl-page:: 49
				  hl-color:: purple
				  id:: 63e7cba0-146c-4506-ab17-9de71254a71b
				- 学习预测不相互排斥的类别的问题称为多标签分类（multi-label classification）。举个例子，人们在技术博客上贴的标签，比如“机器学习”、“技术”、“小工具”、“编程语言”、“Linux”、“云计算”、“AWS”。一篇典型的文章可能会用5-10个标签，因为这些概念是相互关联的。
				  ls-type:: annotation
				  hl-page:: 49
				  hl-color:: purple
				  id:: 63e7cc26-21eb-4c0d-9dcb-b337c0cb8bd4
			- ### 搜索
			  ls-type:: annotation
			  hl-page:: 50
			  hl-color:: green
			  id:: 63e7cc55-7322-4e32-adc9-dda8ac07cc38
				- 有时，我们不仅仅希望输出为一个类别或一个实值。在信息检索领域，我们希望对一组项目进行排序。以网络搜索为例，我们的目标不是简单的“查询（query）-网⻚（page）”分类，而是在海量搜索结果中找到用戶最需要的那部分。搜索结果的排序也十分重要，我们的学习算法需要输出有序的元素子集。
				  ls-type:: annotation
				  hl-page:: 50
				  hl-color:: purple
				  id:: 63e7cc7c-3eee-4a66-b3d9-e23e3c62e18a
			- ### 推荐系统
			  ls-type:: annotation
			  hl-page:: 50
			  hl-color:: green
			  id:: 63e7cda0-eba9-4511-823b-b9c3f8971024
				- 另一类与搜索和排名相关的问题是推荐系统（recommender system），它的目标是向特定用戶进行“个性化”推荐。
				  ls-type:: annotation
				  hl-page:: 50
				  hl-color:: purple
				  id:: 63e7cdb8-f1e0-4d29-8082-2437f9d1c624
			- ### 序列学习
			  ls-type:: annotation
			  hl-page:: 51
			  hl-color:: green
			  id:: 63e7d03b-9eae-462c-864a-f838b7bca32f
				- 以上大多数问题都具有固定大小的输入和产生固定大小的输出。
				  ls-type:: annotation
				  hl-page:: 51
				  hl-color:: purple
				  id:: 63e7d04a-f5ac-4068-bdc6-b419b461ebb7
				- 如果输入的样本之间没有任何关系，以上模型可能完美无缺。但是如果输入是连续的，我们的模型可能就需要拥有“记忆”功能。比如，我们该如何处理视频片段呢？在这种情况下，每个视频片段可能由不同数量的帧组成。通过前一帧的图像，我们可能对后一帧中发生的事情更有把握。语言也是如此，机器翻译的输入和输出都为文字序列。
				  ls-type:: annotation
				  hl-page:: 51
				  hl-color:: purple
				  id:: 63e7d103-7ad6-4c9f-974f-6e112604f686
					- 我们的车道线检测的模型，前后两帧应该也是需要记忆的，是有关联的。车道线是连续的，不可能会跳变。
				- #### 标记和解析
				  ls-type:: annotation
				  hl-page:: 52
				  hl-color:: green
				  id:: 63e85bfa-065d-4a5c-9c05-883a97ee54ac
					- 这涉及到用属性注释文本序列。换句话说，输入和输出的数量基本上是相同的。
					  ls-type:: annotation
					  hl-page:: 52
					  hl-color:: purple
					  id:: 63e85c48-f29b-4dfc-bc64-804673c14419
					- 下面是一个非常简单的示例，它使用“标记”来注释一个句子，该标记指示哪些单词引用命名实体。标记为“Ent”，是实体（entity）的简写。
					  ls-type:: annotation
					  hl-page:: 52
					  hl-color:: purple
					  id:: 63e85dbf-eb8e-4dca-988f-900b204d453c
						- [:span]
						  ls-type:: annotation
						  hl-page:: 52
						  hl-color:: purple
						  id:: 63e85dd0-39d4-4570-a8a6-80f939ea2104
						  hl-type:: area
						  hl-stamp:: 1676172751871
					- #### 自动语音识别
					  ls-type:: annotation
					  hl-page:: 52
					  hl-color:: green
					  id:: 63e85ddb-dbf5-4c91-957e-b7b2df7c9899
						- 在语音识别中，输入序列是说话人的录音（如 图1.3.5 所示），输出序列是说话人所说内容的文本记录
						  ls-type:: annotation
						  hl-page:: 52
						  hl-color:: purple
						  id:: 63e85de9-0dce-4da8-ae0b-cb6d3ef72afe
						- 是“序列到序列”的学习问题，其中输出比输入短得多。
						  ls-type:: annotation
						  hl-page:: 52
						  hl-color:: purple
						  id:: 63e85dfc-2947-49f2-a5f6-8ccb5cb6db1b
					- #### 文本到语音
					  ls-type:: annotation
					  hl-page:: 52
					  hl-color:: green
					  id:: 63e85e05-bf1a-4fe1-ba24-9e4903128fc8
						- 输入是文本，输出是音频文件
						  ls-type:: annotation
						  hl-page:: 52
						  hl-color:: purple
						  id:: 63e85e18-9f69-4fa1-9afe-a78b7f066f68
					- #### 机器翻译
					  ls-type:: annotation
					  hl-page:: 52
					  hl-color:: green
					  id:: 63e85e1e-831e-4b61-8a80-304283e49258
						- 在机器翻译中，颠倒输入和输出的顺序非常重要。
						  ls-type:: annotation
						  hl-page:: 52
						  hl-color:: purple
						  id:: 63e85e49-c105-4528-b794-34d8b07a4827
		- ## 1.3.2 无监督学习
		  ls-type:: annotation
		  hl-page:: 53
		  hl-color:: red
		  id:: 63e85e7c-6ef4-4510-92ab-ec6195d5c1a3
			- 到目前为止，所有的例子都与监督学习有关，即我们向模型提供巨大数据集：每个样本包含特征和相应标签值。
			  ls-type:: annotation
			  hl-page:: 53
			  hl-color:: purple
			  id:: 63e85e94-c0d6-49eb-8155-ad3dde25fd3c
			- “监督学习”模型像一个打工仔，有一份极其专业的工作和一位极其平庸的老板。老板站在身后，准确地告诉模型在每种情况下应该做什么，直到模型学会从情况到行动的映射。取悦这位老板很容易，只需尽快识别出模式并模仿他们的行为即可。
			  ls-type:: annotation
			  hl-page:: 53
			  hl-color:: purple
			  id:: 63e85ea8-65c5-463d-ac57-2891654cf051
			- 如果你的工作没有十分具体的目标，你就需要“自发”地去学习了。（如果你打算成为一名数据科学家，你最好培养这个习惯。）比如，你的老板可能会给你一大堆数据，然后让你用它做一些数据科学研究，却没有对结果有要求。我们称这类数据中不含有“目标”的机器学习问题为无监督学习（unsupervised learning），
			  ls-type:: annotation
			  hl-page:: 53
			  hl-color:: purple
			  id:: 63e85ec5-8678-40e8-b22d-43018a59b3ec
			- ### 聚类（clustering）问题
			  ls-type:: annotation
			  hl-page:: 53
			  hl-color:: green
			  id:: 63e85ed3-4ddc-4ac7-9543-67123c31e577
				- 没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成⻛景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用戶的网⻚浏览记录，我们能否将具有相似行为的用戶聚类呢？
				  ls-type:: annotation
				  hl-page:: 53
				  hl-color:: purple
				  id:: 63e85ee4-555d-4365-a137-43685399dc0b
			- ### 主成分分析（principal component analysis）问题
			  ls-type:: annotation
			  hl-page:: 53
			  hl-color:: green
			  id:: 63e85eea-ce8e-48c3-9b3c-20e04595d863
				- 我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。再比如，裁缝们已经开发出了一小部分参数，这些参数相当准确地描述了人体的形状，以适应衣服的需要。
				  ls-type:: annotation
				  hl-page:: 53
				  hl-color:: purple
				  id:: 63e85f2d-7b4a-4628-aafe-4b1d88a2d9a1
			- ### 因果关系（causality）和概率图模型（probabilistic graphical models）问题
			  ls-type:: annotation
			  hl-page:: 53
			  hl-color:: green
			  id:: 63e85f35-1197-484b-93aa-24e5fcadf64d
			- ### 生成对抗性网络（generative adversarial networks）
			  ls-type:: annotation
			  hl-page:: 53
			  hl-color:: green
			  id:: 63e85f67-c20d-4dfa-84a2-15d3b5def31e
		- ## 1.3.3 与环境互动
		  ls-type:: annotation
		  hl-page:: 53
		  hl-color:: red
		  id:: 63e85f84-8aa8-420c-bcd5-e7d65f2ba871
			- 机器学习的输入（数据）来自哪里？机器学习的输出又将去往何方？到目前为止，不管是监督学习还是无监督学习，我们都会预先获取大量数据，然后启动模型，不再与环境交互。这里所有学习都是在算法与环境断开后进行的，被称为离线学习（offline learning）。
			  ls-type:: annotation
			  hl-page:: 53
			  hl-color:: purple
			  id:: 63e85fa2-79f7-4906-b5b8-e30f88e58bf4
			- [:span]
			  ls-type:: annotation
			  hl-page:: 54
			  hl-color:: purple
			  id:: 63e85fb1-ebdf-4556-994d-189b48570f95
			  hl-type:: area
			  hl-stamp:: 1676173232723
		- ## 1.3.4 强化学习
		  ls-type:: annotation
		  hl-page:: 54
		  hl-color:: red
		  id:: 63e85fec-2569-4049-b85b-aa42a8954179
	- # 1.2 关键组件
	  ls-type:: annotation
	  hl-page:: 43
	  hl-color:: yellow
	  id:: 63e7c219-0045-45fc-819b-93545b242b3c
	  collapsed:: true
		- hl-page:: 43
		  ls-type:: annotation
		  id:: 63e7c257-06aa-41ef-954c-983b10129f1b
		  hl-color:: purple
		  1. 我们可以学习的数据（data）。
		  2. 如何转换数据的模型（model）。
		  3. 一个目标函数（objective function），用来量化模型的有效性。
		  4. 调整模型参数以优化目标函数的算法（algorithm）。
		- ## 1.2.1 数据
		  ls-type:: annotation
		  hl-page:: 44
		  hl-color:: red
		  id:: 63e7c24b-12db-45ec-8f4f-6536c7a6d9c5
		- ## 1.2.2 模型
		  ls-type:: annotation
		  hl-page:: 45
		  hl-color:: red
		  id:: 63e7c28f-77a2-4691-8f44-44ec1703b0b4
		- ## 1.2.3 目标函数
		  ls-type:: annotation
		  hl-page:: 45
		  hl-color:: red
		  id:: 63e7c296-1eff-4b1b-8b7a-1ad7ec67ee41
			- 在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，我们称之为目标函数（objective function）。
			  ls-type:: annotation
			  hl-page:: 45
			  hl-color:: purple
			  id:: 63e7c2f8-05b9-4c37-9187-64615dceb9ae
			- 我们通常定义一个目标函数，并希望优化它到最低点。因为越低越好，所以这些函数有时被称为损失函数（loss function，或cost function）。但这只是一个惯例，你也可以取一个新的函数，优化到它的最高点。这两个函数本质上是相同的，只是翻转一下符号。
			  ls-type:: annotation
			  hl-page:: 45
			  hl-color:: purple
			  id:: 63e7c35a-ee96-4ff6-beab-26f615e54bab
		- ## 1.2.4 优化算法
		  ls-type:: annotation
		  hl-page:: 45
		  hl-color:: red
		  id:: 63e7c29c-61e9-4030-8c9c-5bf30b74de5f
			- 一旦我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，我们接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。深度学习中，大多流行的优化算法通常基于一种基本方法‒梯度下降（gradient descent）。简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果你仅对该参数进行少量变动，训练集损失会朝哪个方向移动。然后，它在可以减少损失的方向上优化参数。
			  ls-type:: annotation
			  hl-page:: 45
			  hl-color:: purple
			  id:: 63e7c41c-bece-4721-b912-9b5419c711da
	- *机器学习*（machine learning，ML）是一类强大的可以从经验中学习的技术。通常采用观测数据或与环境交互的形式，机器学习算法会积累更多的经验，其性能也会逐步提高。 相反，对于刚刚所说的电子商务平台，如果它一直执行相同的业务逻辑，无论积累多少经验，都不会自动提高，除非开发人员认识到问题并更新软件。
	- ## 1.1.  日常生活中的机器学习
	  collapsed:: true
		- 通常，即使我们不知道怎样明确地告诉计算机如何从输入映射到输出，大脑仍然能够自己执行认知功能。 换句话说，即使我们不知道如何编写计算机程序来识别“Alexa”这个词，大脑自己也能够识别它。 有了这一能力，我们就可以收集一个包含大量音频样本的*数据集*（dataset），并对包含和不包含唤醒词的样本进行标记。 利用机器学习算法，我们不需要设计一个“明确地”识别唤醒词的系统。 相反，我们只需要定义一个灵活的程序算法，其输出由许多*参数*（parameter）决定，然后使用数据集来确定当下的“最佳参数集”，这些参数通过某种性能度量方式来达到完成任务的最佳性能。
		- 那么到底什么是参数呢？
			- 参数可以被看作旋钮，旋钮的转动可以调整程序的行为。 任一调整参数后的程序被称为*模型*（model）。 通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。 使用数据集来选择参数的元程序被称为*学习算法*（learning algorithm）。
		- 但如果模型所有的按钮（模型参数）都被随机设置，就不太可能识别出“Alexa”“Hey Siri”或任何其他单词。 在机器学习中，*学习*（learning）是一个训练模型的过程。 通过这个过程，我们可以发现正确的参数集，从而使模型强制执行所需的行为。 换句话说，我们用数据*训练*（train）模型。
		- 训练过程通常包含如下步骤：
			- 从一个随机初始化参数的模型开始，这个模型基本没有“智能”；
			- 获取一些数据样本（例如，音频片段以及对应的是或否标签）；
			- 调整参数，使模型在这些样本中表现得更好；
			- 重复第（2）步和第（3）步，直到模型在任务中的表现令人满意。
		- 如果我们用一个巨大的带标签的数据集，它很可能可以“学习”识别唤醒词。 这种“通过用数据集来确定程序行为”的方法可以被看作*用数据编程*（programming with data）。 比如，我们可以通过向机器学习系统，提供许多猫和狗的图片来设计一个“猫图检测器”。 检测器最终可以学会：如果输入是猫的图片就输出一个非常大的正数，如果输入是狗的图片就会输出一个非常小的负数。 如果检测器不确定输入的图片中是猫还是狗，它会输出接近于零的数……
- # 2. 预备知识
	- ## 2.1 数据操作
	  hl-page:: 64
	  ls-type:: annotation
	  id:: 63e87506-22df-4456-a200-f4a26f17cdde
	  hl-color:: yellow
		- 我们需要做两件重要的事：（1）获取数据；（2）将数据读入计算机后对其进行处理。
		  ls-type:: annotation
		  hl-page:: 64
		  hl-color:: purple
		  id:: 63e87531-3580-4a5b-b644-c7055b9216f9
		- ### 2.1.1 入⻔
		  hl-page:: 64
		  ls-type:: annotation
		  id:: 63e8776b-959b-48a1-981a-2f1986d63f41
		  hl-color:: red